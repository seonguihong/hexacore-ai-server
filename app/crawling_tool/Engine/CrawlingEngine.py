import re
from attr import attr
import requests
from bs4 import BeautifulSoup

from app.post_analysis.infrastructure.service.openai_service_impl import OpenAIServiceImpl


class CrawlingEngine:

    def __init__(self,url: str):
        self.headers = {"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"}
        self.OAS = OpenAIServiceImpl()

    def get_page_to_list(self):
        links = []
        for i in range(1, 6):
            url = f"https://www.paxnet.co.kr/tbbs/list?tbbsType=L&id=N11023&page={i}"
            res = requests.get(url, headers=self.headers)
            res.raise_for_status()
            soup = BeautifulSoup(res.text, "lxml")

            soup = BeautifulSoup(res.text, "lxml")

            articles = soup.find_all("p", attrs={"class": "tit"})

            for article in articles:
                atag = article.find("a", attrs={"class": "best-title"})
                if atag:
                    command = atag.get("href")

                    match = re.search(r"orgBbsWrtView\((\d+),\s*'([^']+)'\)", command)
                    if match:
                        seq = match.group(1)
                        board_id = match.group(2)
                        view_url = f"https://www.paxnet.co.kr/tbbs/view?id={board_id}&seq={seq}&page={i}"
                        links.append(view_url)

            for link in links:
                print("ğŸ¯ ìŠ¤í¬ë© ì¤‘:", link)
                res = requests.get(link, headers=self.headers)
                soup = BeautifulSoup(res.text, "lxml")
                test=self.OAS.analyze_stock_post(link.get_text())
                print(test)


                # ì œëª©
                title_tag = soup.find("h1")
                title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"
                print(title)
                # ë³¸ë¬¸
                content_div = soup.find("div", attrs={"class": "board-view-cont"})
                if content_div:  # None ì²´í¬ í•„ìˆ˜
                   p_tags = content_div.find_all("p")  # ìì‹ p íƒœê·¸ ì „ë¶€ ê°€ì ¸ì˜¤ê¸°
                   print(p_tags)
                   if p_tags:
                       for p in p_tags:
                           print(p)
                           text = p.get_text(strip=True)
                           print(text)
                   else:
                       # p íƒœê·¸ê°€ ì—†ìœ¼ë©´ div ì•ˆì˜ í…ìŠ¤íŠ¸ ì „ì²´ ì¶œë ¥
                       text = content_div.get_text(strip=True)
                       print(text)
                else:
                    print("ë³¸ë¬¸ ì—†ìŒ")

    # ë‚´ì¼ ì½”ë“œ í•©ì§ˆê²ƒ
    # íŒ€ì¥ë‹˜ í•œí…Œ í¬ë¡¤ë§ 5í˜ì´ì§€ë¡œ íƒ€ì—½ ì´ìœ  ë„ˆë¬´ ì˜¤ë˜ê±¸ë¦¼
    # í˜„ì¬ í‰ìŠ¤ë„· ê²Œì‹œíŒ ì œëª©ê³¼ ë‚´ìš©ì„ ê°€ì ¸ì˜´. ë”í•„ìš”í•œ ì»¬ëŸ¼ í™•ì‹¤í•˜ê²Œ ì •ë¦¬ í•„ìš”.
    # ì–´ë–¤ê°’ìœ¼ë¡œ ë˜ì €ì£¼ë©´ ë˜ëŠ”ì§€. #ì–´ì œë°°ìš´ ë¶„ì„ ì‚¬ìš©ì•ˆí–ˆëŠ”ë° ê´œì°®ì€ì§€.
